{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPd8VCNJZKc8U2P236FDZ7k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amithchintu/Files-Exceptional-Handling/blob/main/Files_%26_Exceptional_Handling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.\n",
        "\n",
        "# In Python, choosing between multithreading and multiprocessing depends on the nature of the tasks you need to perform. Here’s a detailed look at when each approach is preferable:\n",
        "\n",
        "# Multithreading:\n",
        "\n",
        "# Preferable for:\n",
        "\n",
        "# I/O-bound tasks: Tasks that spend a lot of time waiting for I/O operations, such as reading/writing files, network requests, or database queries. Since these tasks are often idle, multiple threads can run concurrently without significant performance hits.\n",
        "# Shared memory space: When tasks need to share data frequently, multithreading is more efficient because threads share the same memory space, reducing the overhead of inter-process communication.\n",
        "# Lightweight tasks: When tasks are relatively lightweight and do not require significant CPU resources, multithreading can be more efficient due to lower overhead in creating and managing threads.\n",
        "\n",
        "# Examples:\n",
        "\n",
        "# Web servers handling multiple client requests.\n",
        "# GUI applications where the main thread handles user interactions while background threads perform tasks like loading data.\n",
        "\n",
        "# Multiprocessing\n",
        "\n",
        "# Preferable for:\n",
        "\n",
        "# CPU-bound tasks: Tasks that require heavy computation and can benefit from parallel execution on multiple CPU cores. Multiprocessing allows true parallelism by utilizing multiple processors.\n",
        "# Independent tasks: When tasks are independent and do not need to share data frequently, multiprocessing is advantageous as each process has its own memory space.\n",
        "# Avoiding GIL limitations: In languages like Python, the Global Interpreter Lock (GIL) can be a bottleneck for CPU-bound tasks. Multiprocessing bypasses this limitation by using separate memory spaces for each process.\n",
        "\n",
        "# Examples:\n",
        "\n",
        "# Scientific computations, such as simulations or data analysis.\n",
        "# Video encoding or image processing tasks that can be divided into smaller, independent chunks.\n",
        "\n",
        "# Summary\n",
        "# Multithreading is ideal for I/O-bound tasks and scenarios where tasks need to share data frequently.\n",
        "# Multiprocessing is better suited for CPU-bound tasks and scenarios where tasks are independent and can run in parallel without frequent data sharing."
      ],
      "metadata": {
        "id": "yGcWoDCJGm1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
        "\n",
        "# A process pool is a collection of worker processes that are managed by a pool manager to execute tasks concurrently. It is a high-level way to parallelize the execution of a function across multiple input values, distributing the input data across processes (data parallelism).\n",
        "\n",
        "# How Process Pools Work\n",
        "# Initialization: A fixed number of worker processes are created and maintained in the pool.\n",
        "# Task Submission: Tasks are submitted to the pool, which then assigns them to the available worker processes.\n",
        "# Execution: Each worker process executes the assigned task independently.\n",
        "# Result Collection: Once a task is completed, the result is collected and returned to the main process.\n",
        "\n",
        "# Benefits of Using Process Pools\n",
        "# Efficient Resource Management: By reusing a fixed number of processes, process pools avoid the overhead of creating and destroying processes repeatedly.\n",
        "# Load Balancing: Tasks are distributed among the worker processes, ensuring that all processes are utilized efficiently.\n",
        "# Simplified Concurrency: Process pools abstract the complexity of managing multiple processes, making it easier to implement parallel processing.\n",
        "# Scalability: Process pools can handle a large number of tasks by queuing them and processing them as worker processes become available.\n",
        "\n",
        "# Example in Python\n",
        "# In Python, the multiprocessing module provides a Pool class to create and manage a process pool. Here’s a simple example:"
      ],
      "metadata": {
        "id": "eD_rq9QII6iH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sNYM6zAFP4o",
        "outputId": "26b07a79-076d-4a9b-8ede-d006ebedf174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ],
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    with Pool(4) as p:  # Create a pool with 4 worker processes\n",
        "        results = p.map(square, [1, 2, 3, 4, 5])\n",
        "    print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In this example:\n",
        "\n",
        "# A pool of 4 worker processes is created.\n",
        "# The square function is applied to each element in the list [1, 2, 3, 4, 5] concurrently.\n",
        "# The results are collected and printed."
      ],
      "metadata": {
        "id": "lZm-6HfJKk-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "# A process pool helps manage multiple processes efficiently by reusing a fixed number of worker processes, balancing the load, and simplifying the implementation of parallel processing. This approach is particularly useful for tasks that can be executed independently and benefit from parallel execution."
      ],
      "metadata": {
        "id": "JcfNfVohK1Jk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Explain what multiprocessing is and why it is used in Python programs.\n",
        "# Multiprocessing is a technique that allows a program to run multiple processes simultaneously. Each process runs independently and has its own memory space. This is different from multithreading, where threads share the same memory space.\n",
        "# Use Multiprocessing in Python\n",
        "# True Parallelism: Multiprocessing allows Python programs to achieve true parallelism by utilizing multiple CPU cores. This is particularly important for CPU-bound tasks that require significant computational power.\n",
        "# Bypassing the GIL: Python’s Global Interpreter Lock (GIL) can be a bottleneck for CPU-bound tasks in multithreaded programs. The GIL ensures that only one thread executes Python bytecode at a time, which can limit performance. Multiprocessing bypasses the GIL by using separate memory spaces for each process, allowing multiple processes to run concurrently on different CPU cores.\n",
        "# Improved Performance: For tasks that can be divided into smaller, independent chunks, multiprocessing can significantly improve performance by distributing the workload across multiple processes.\n",
        "# Fault Isolation: Since each process runs independently, a crash in one process does not affect the others. This isolation can make programs more robust and easier to debug.\n",
        "\n",
        "# Examples of Use Cases\n",
        "# Scientific Computing: Tasks like simulations, data analysis, and numerical computations that require heavy CPU usage.\n",
        "# Image and Video Processing: Operations that can be parallelized, such as filtering, transformation, and encoding.\n",
        "# Web Scraping: Fetching data from multiple web pages concurrently.\n",
        "# Machine Learning: Training models on large datasets by distributing the workload across multiple processes.\n",
        "\n",
        "# Example in Python\n",
        "# Here’s a simple example using the multiprocessing module in Python:\n"
      ],
      "metadata": {
        "id": "cX1BMSqiLPIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process\n",
        "\n",
        "def print_square(num):\n",
        "    print(f'Square: {num * num}')\n",
        "\n",
        "def print_cube(num):\n",
        "    print(f'Cube: {num * num * num}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    p1 = Process(target=print_square, args=(10,))\n",
        "    p2 = Process(target=print_cube, args=(10,))\n",
        "\n",
        "    p1.start()\n",
        "    p2.start()\n",
        "\n",
        "    p1.join()\n",
        "    p2.join()"
      ],
      "metadata": {
        "id": "WWFGANvvKOT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In this example:\n",
        "\n",
        "# Two processes are created to print the square and cube of a number.\n",
        "# Each process runs independently and concurrently.\n",
        "\n",
        "# Summary\n",
        "# Multiprocessing in Python is used to achieve true parallelism, bypass the GIL, improve performance for CPU-bound tasks, and provide fault isolation. It is particularly useful for tasks that can be divided into independent chunks and benefit from parallel execution."
      ],
      "metadata": {
        "id": "A3ZDiOTcNFti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock\n",
        "\n",
        "# Python program that demonstrates multithreading with one thread adding numbers to a list and another thread removing numbers from the list. We’ll use threading.Lock to avoid race conditions."
      ],
      "metadata": {
        "id": "s9a--uQlNe_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared list\n",
        "shared_list = []\n",
        "\n",
        "# Lock object to prevent race conditions\n",
        "lock = threading.Lock()\n",
        "\n",
        "def add_numbers():\n",
        "    for i in range(10):\n",
        "        time.sleep(0.1)  # Simulate some work\n",
        "        with lock:\n",
        "            shared_list.append(i)\n",
        "            print(f'Added {i}, List: {shared_list}')\n",
        "\n",
        "def remove_numbers():\n",
        "    for i in range(10):\n",
        "        time.sleep(0.15)  # Simulate some work\n",
        "        with lock:\n",
        "            if shared_list:\n",
        "                removed = shared_list.pop(0)\n",
        "                print(f'Removed {removed}, List: {shared_list}')\n",
        "\n",
        "# Create threads\n",
        "thread1 = threading.Thread(target=add_numbers)\n",
        "thread2 = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Start threads\n",
        "thread1.start()\n",
        "thread2.start()\n",
        "\n",
        "# Wait for threads to complete\n",
        "thread1.join()\n",
        "thread2.join()\n",
        "\n",
        "print('Final List:', shared_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNF1t9F5OHYM",
        "outputId": "8ef4a101-be15-40cc-93c6-a86abaa44451"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 0, List: [0]\n",
            "Removed 0, List: []\n",
            "Added 1, List: [1]\n",
            "Removed 1, List: []\n",
            "Added 2, List: [2]\n",
            "Added 3, List: [2, 3]\n",
            "Removed 2, List: [3]\n",
            "Added 4, List: [3, 4]\n",
            "Removed 3, List: [4]\n",
            "Added 5, List: [4, 5]\n",
            "Added 6, List: [4, 5, 6]\n",
            "Removed 4, List: [5, 6]\n",
            "Added 7, List: [5, 6, 7]\n",
            "Removed 5, List: [6, 7]\n",
            "Added 8, List: [6, 7, 8]\n",
            "Added 9, List: [6, 7, 8, 9]\n",
            "Removed 6, List: [7, 8, 9]\n",
            "Removed 7, List: [8, 9]\n",
            "Removed 8, List: [9]\n",
            "Removed 9, List: []\n",
            "Final List: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation:\n",
        "# Shared List: shared_list is the list that both threads will modify.\n",
        "# Lock Object: lock is a threading.Lock object used to ensure that only one thread can modify the list at a time.\n",
        "# Add Numbers Function: This function adds numbers to the list. It acquires the lock before modifying the list to prevent race conditions.\n",
        "# Remove Numbers Function: This function removes numbers from the list. It also acquires the lock before modifying the list to ensure thread safety.\n",
        "# Threads Creation: Two threads are created, one for adding numbers and one for removing numbers.\n",
        "# Start and Join Threads: The threads are started and then joined to ensure the main program waits for both threads to complete.\n",
        "\n",
        "# Avoiding Race Conditions:\n",
        "# The with lock: statement ensures that the lock is acquired before modifying the list and released after the modification is done. This prevents both threads from modifying the list simultaneously, avoiding race conditions.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lZV6_NHFOGpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Describe the methods and tools available in Python for safely sharing data between threads and processes.\n",
        "# In Python, safely sharing data between threads and processes is crucial to avoid race conditions and ensure data integrity. Here are some methods and tools available for this purpose:\n",
        "# Sharing Data Between Threads\n",
        "# threading.Lock:\n",
        "# Purpose: Ensures that only one thread can access a shared resource at a time.\n",
        "# Usage: Wrap the critical section of code with lock.acquire() and lock.release() or use the with lock: context manager.\n",
        "# Example:"
      ],
      "metadata": {
        "id": "HJd3IdRrOsHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "lock = threading.Lock()\n",
        "shared_data = []\n",
        "\n",
        "def thread_safe_append(data):\n",
        "    with lock:\n",
        "        shared_data.append(data)"
      ],
      "metadata": {
        "id": "z-XgFw_dPdWp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# threading.RLock (Reentrant Lock):\n",
        "# Purpose: Allows a thread to acquire the same lock multiple times.\n",
        "# Usage: Similar to threading.Lock, but useful in recursive functions.\n",
        "# Example:\n"
      ],
      "metadata": {
        "id": "Xt9uxqRoPlvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "rlock = threading.RLock()\n",
        "shared_data = []\n",
        "\n",
        "def thread_safe_append(data):\n",
        "    with rlock:\n",
        "        shared_data.append(data)"
      ],
      "metadata": {
        "id": "jqbQ-UnlPfvS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# threading.Event:\n",
        "# Purpose: Allows threads to wait for an event to be set.\n",
        "# Usage: Useful for signaling between threads.\n",
        "# Example:"
      ],
      "metadata": {
        "id": "REGMLsiAP8v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "event = threading.Event()\n",
        "\n",
        "def wait_for_event():\n",
        "    event.wait()\n",
        "    print(\"Event has been set!\")\n",
        "\n",
        "threading.Thread(target=wait_for_event).start()\n",
        "event.set()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWoSE2SYQJJY",
        "outputId": "8547d789-b7df-4fdf-9350-5e8234e088aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Event has been set!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# queue.Queue:\n",
        "# Purpose: Provides a thread-safe FIFO queue.\n",
        "# Usage: Threads can safely put and get items from the queue.\n",
        "# Example:"
      ],
      "metadata": {
        "id": "nr0X8KlcQixU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import queue\n",
        "\n",
        "q = queue.Queue()\n",
        "\n",
        "def producer():\n",
        "    for i in range(5):\n",
        "        q.put(i)\n",
        "        print(f\"Produced {i}\")\n",
        "\n",
        "def consumer():\n",
        "    while True:\n",
        "        item = q.get()\n",
        "        if item is None:\n",
        "            break\n",
        "        print(f\"Consumed {item}\")\n",
        "\n",
        "threading.Thread(target=producer).start()\n",
        "threading.Thread(target=consumer).start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t9_1kwHP3Y3",
        "outputId": "fe1e9390-a106-4b95-8e08-f6b006d79dcb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Produced 0\n",
            "Produced 1\n",
            "Produced 2\n",
            "Produced 3\n",
            "Produced 4\n",
            "Consumed 0\n",
            "Consumed 1\n",
            "Consumed 2\n",
            "Consumed 3\n",
            "Consumed 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sharing Data Between Processes\n",
        "# multiprocessing.Queue:\n",
        "# Purpose: Provides a process-safe FIFO queue.\n",
        "# Usage: Processes can safely put and get items from the queue.\n",
        "# Example:\n",
        "\n"
      ],
      "metadata": {
        "id": "vrE2xo99Q2sA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def producer(q):\n",
        "    for i in range(5):\n",
        "        q.put(i)\n",
        "        print(f\"Produced {i}\")\n",
        "\n",
        "def consumer(q):\n",
        "    while True:\n",
        "        item = q.get()\n",
        "        if item is None:\n",
        "            break\n",
        "        print(f\"Consumed {item}\")\n",
        "\n",
        "q = Queue()\n",
        "p1 = Process(target=producer, args=(q,))\n",
        "p2 = Process(target=consumer, args=(q,))\n",
        "\n",
        "p1.start()\n",
        "p2.start()\n",
        "\n",
        "p1.join()\n",
        "q.put(None)  # Signal the consumer to stop\n",
        "p2.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIZ5PMQBQvno",
        "outputId": "b1279efb-efd6-4db8-d672-a5d5586c8f39"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Produced 0\n",
            "Produced 1Consumed 0\n",
            "Produced 2\n",
            "\n",
            "Consumed 1Produced 3\n",
            "Produced 4\n",
            "\n",
            "Consumed 2\n",
            "Consumed 3\n",
            "Consumed 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# multiprocessing.Pipe:\n",
        "# Purpose: Provides a two-way communication channel between processes.\n",
        "# Usage: Processes can send and receive messages through the pipe.\n",
        "# Example:\n"
      ],
      "metadata": {
        "id": "U7mc-na5RVDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Pipe\n",
        "\n",
        "def sender(conn):\n",
        "    conn.send(\"Hello from sender\")\n",
        "    conn.close()\n",
        "\n",
        "def receiver(conn):\n",
        "    msg = conn.recv()\n",
        "    print(f\"Received: {msg}\")\n",
        "\n",
        "parent_conn, child_conn = Pipe()\n",
        "p1 = Process(target=sender, args=(child_conn,))\n",
        "p2 = Process(target=receiver, args=(parent_conn,))\n",
        "\n",
        "p1.start()\n",
        "p2.start()\n",
        "\n",
        "p1.join()\n",
        "p2.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfhsO2HuRPTZ",
        "outputId": "65b9113f-5a69-46c3-9fb4-1fe5995372fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received: Hello from sender\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# multiprocessing.Value and multiprocessing.Array:\n",
        "# Purpose: Share simple data types and arrays between processes.\n",
        "# Usage: Use Value for single data items and Array for arrays.\n",
        "# Example:\n"
      ],
      "metadata": {
        "id": "7Z6aMfPsSP6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Value, Array\n",
        "\n",
        "def modify_shared_data(val, arr):\n",
        "    val.value = 42\n",
        "    for i in range(len(arr)):\n",
        "        arr[i] = -arr[i]\n",
        "\n",
        "shared_val = Value('i', 0)\n",
        "shared_arr = Array('i', range(5))\n",
        "\n",
        "p = Process(target=modify_shared_data, args=(shared_val, shared_arr))\n",
        "p.start()\n",
        "p.join()\n",
        "\n",
        "print(shared_val.value)\n",
        "print(shared_arr[:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf8vqqYBRlcd",
        "outputId": "1b425796-11c4-442c-b127-aff5d41470cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n",
            "[0, -1, -2, -3, -4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "# Threads: Use threading.Lock, threading.RLock, threading.Event, and queue.Queue for safe data sharing.\n",
        "# Processes: Use multiprocessing.Queue, multiprocessing.Pipe, multiprocessing.Value, and multiprocessing.Array for inter-process communication and data sharing."
      ],
      "metadata": {
        "id": "ys5mxxAZS1Tw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.\n",
        "# Handling exceptions in concurrent programs is crucial for several reasons:\n",
        "# Why It’s Crucial\n",
        "# Preventing Program Crashes: Unhandled exceptions in one thread or process can cause the entire program to crash. This is especially problematic in concurrent programs where multiple tasks are running simultaneously.\n",
        "# Maintaining Data Integrity: Exceptions can lead to inconsistent or corrupted data if not handled properly. For example, if a thread is updating a shared resource and an exception occurs, the resource might be left in an inconsistent state.\n",
        "# Ensuring Robustness: Proper exception handling ensures that the program can recover from errors and continue running. This is important for long-running applications like servers or background services.\n",
        "# Debugging and Logging: Handling exceptions allows you to log errors and gather information about what went wrong. This is essential for debugging and improving the reliability of the program.\n",
        "# Techniques for Handling Exceptions in Concurrent Programs\n",
        "# Try-Except Blocks:\n",
        "# Usage: Surround critical sections of code with try-except blocks to catch and handle exceptions.\n",
        "# Example:"
      ],
      "metadata": {
        "id": "iApF8163TJGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def thread_function():\n",
        "    try:\n",
        "        # Critical section\n",
        "        pass\n",
        "    except Exception as e:\n",
        "        print(f\"Exception in thread: {e}\")\n",
        "\n",
        "thread = threading.Thread(target=thread_function)\n",
        "thread.start()\n",
        "thread.join()"
      ],
      "metadata": {
        "id": "XHLYoXCUSpVk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Centralized Exception Handling:\n",
        "# Usage: Designate a central point in your application to handle exceptions, such as an exception handler function or class.\n",
        "# Example:"
      ],
      "metadata": {
        "id": "0R4J_WceUhMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def handle_exception(exc_type, exc_value, exc_traceback):\n",
        "    print(f\"Exception: {exc_value}\")\n",
        "\n",
        "def thread_function():\n",
        "    try:\n",
        "        # Critical section\n",
        "        pass\n",
        "    except Exception as e:\n",
        "        handle_exception(*sys.exc_info())\n",
        "\n",
        "thread = threading.Thread(target=thread_function)\n",
        "thread.start()\n",
        "thread.join()"
      ],
      "metadata": {
        "id": "2ymgUWpfUaAZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thread-Safe Queues:\n",
        "# Usage: Use thread-safe queues to communicate exceptions between threads.\n",
        "# Example:"
      ],
      "metadata": {
        "id": "daf8jszmVYF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import queue\n",
        "\n",
        "def worker(q):\n",
        "    try:\n",
        "        # Critical section\n",
        "        pass\n",
        "    except Exception as e:\n",
        "        q.put(e)\n",
        "\n",
        "q = queue.Queue()\n",
        "thread = threading.Thread(target=worker, args=(q,))\n",
        "thread.start()\n",
        "thread.join()\n",
        "\n",
        "if not q.empty():\n",
        "    exception = q.get()\n",
        "    print(f\"Exception: {exception}\")"
      ],
      "metadata": {
        "id": "2B7N2lrpVN-X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Threading.Event:\n",
        "# Usage: Use threading.Event to signal exceptions between threads.\n",
        "# Example:"
      ],
      "metadata": {
        "id": "jfSSJc9FVomI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "exception_event = threading.Event()\n",
        "\n",
        "def worker():\n",
        "    try:\n",
        "        # Critical section\n",
        "        pass\n",
        "    except Exception as e:\n",
        "        exception_event.set()\n",
        "\n",
        "thread = threading.Thread(target=worker)\n",
        "thread.start()\n",
        "thread.join()\n",
        "\n",
        "if exception_event.is_set():\n",
        "    print(\"Exception occurred in thread\")"
      ],
      "metadata": {
        "id": "dAeyzxQ_Vgli"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiprocessing Exception Handling:\n",
        "# Usage: Use multiprocessing.Queue or multiprocessing.Pipe to handle exceptions in multiprocessing.\n",
        "# Example:"
      ],
      "metadata": {
        "id": "iXex9NhgV5Z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def worker(q):\n",
        "    try:\n",
        "        # Critical section\n",
        "        pass\n",
        "    except Exception as e:\n",
        "        q.put(e)\n",
        "\n",
        "q = Queue()\n",
        "p = Process(target=worker, args=(q,))\n",
        "p.start()\n",
        "p.join()\n",
        "\n",
        "if not q.empty():\n",
        "    exception = q.get()\n",
        "    print(f\"Exception: {exception}\")"
      ],
      "metadata": {
        "id": "OBKq8KnzV1u0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "# Handling exceptions in concurrent programs is essential to prevent crashes, maintain data integrity, ensure robustness, and facilitate debugging. Techniques such as try-except blocks, centralized exception handling, thread-safe queues, threading events, and multiprocessing queues or pipes can be used to manage exceptions effectively."
      ],
      "metadata": {
        "id": "-IvqDi5MWRED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
        "# Python program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently using concurrent.futures.ThreadPoolExecutor:"
      ],
      "metadata": {
        "id": "lPmElNIaWZ5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "def factorial(n):\n",
        "    return math.factorial(n)\n",
        "\n",
        "def main():\n",
        "    numbers = range(1, 11)\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        results = list(executor.map(factorial, numbers))\n",
        "\n",
        "    for number, result in zip(numbers, results):\n",
        "        print(f'Factorial of {number} is {result}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az-Msa3xWJxy",
        "outputId": "5913beaa-4bcf-41b7-bbb4-ca169e159fa9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 1 is 1\n",
            "Factorial of 2 is 2\n",
            "Factorial of 3 is 6\n",
            "Factorial of 4 is 24\n",
            "Factorial of 5 is 120\n",
            "Factorial of 6 is 720\n",
            "Factorial of 7 is 5040\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation:\n",
        "# Importing Modules: We import concurrent.futures for managing the thread pool and math for calculating the factorial.\n",
        "# Factorial Function: The factorial function takes a number n and returns its factorial using math.factorial.\n",
        "# Main Function:\n",
        "# Numbers Range: We define a range of numbers from 1 to 10.\n",
        "# ThreadPoolExecutor: We create a thread pool using ThreadPoolExecutor.\n",
        "# Executor Map: We use executor.map to apply the factorial function to each number in the range concurrently. This returns a list of results.\n",
        "# Printing Results: We iterate over the numbers and their corresponding results to print the factorial of each number.\n",
        "# Entry Point: The main function is called if the script is run directly.\n",
        "# This program efficiently calculates the factorials concurrently using a thread pool, demonstrating how concurrent.futures.ThreadPoolExecutor can be used to manage threads."
      ],
      "metadata": {
        "id": "fY4z0AYOXFAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).\n",
        "#  Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. The program also measures the time taken to perform this computation using different pool sizes (2, 4, and 8 processes).\n",
        "\n"
      ],
      "metadata": {
        "id": "IBHeLSIrXqRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "def compute_squares(pool_size):\n",
        "    numbers = range(1, 11)\n",
        "    start_time = time.time()\n",
        "\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        results = pool.map(square, numbers)\n",
        "\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    return results, duration\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pool_sizes = [2, 4, 8]\n",
        "    for size in pool_sizes:\n",
        "        results, duration = compute_squares(size)\n",
        "        print(f\"Pool size: {size}, Results: {results}, Time taken: {duration:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVEAaMkOW6eD",
        "outputId": "cf36b446-5c40-49c0-aa64-d666247c0c44"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size: 2, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0264 seconds\n",
            "Pool size: 4, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0472 seconds\n",
            "Pool size: 8, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.1005 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation:\n",
        "# Importing Modules: We import multiprocessing for creating the process pool and time for measuring the duration.\n",
        "# Square Function: The square function takes a number n and returns its square.\n",
        "# Compute Squares Function:\n",
        "# Numbers Range: We define a range of numbers from 1 to 10.\n",
        "# Time Measurement: We record the start time before creating the pool and the end time after the computation.\n",
        "# Pool Creation: We create a pool with the specified size using multiprocessing.Pool(pool_size).\n",
        "# Mapping Function: We use pool.map to apply the square function to each number in the range concurrently.\n",
        "# Duration Calculation: We calculate the duration of the computation.\n",
        "# Return Results: The function returns the results and the duration.\n",
        "# Main Block:\n",
        "# Pool Sizes: We define a list of pool sizes to test (2, 4, and 8).Loop Through Pool Sizes: For each pool size, we call compute_squares and print the results and the time taken.\n",
        "# This program demonstrates how to use multiprocessing.Pool to perform parallel computations and measure the performance with different pool sizes."
      ],
      "metadata": {
        "id": "nb9Dh45-ZMh8"
      }
    }
  ]
}